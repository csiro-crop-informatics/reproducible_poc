manifest {
  homePage = 'https://github.com/csiro-crop-informatics/reproducible_poc'
  description = 'Nextflow proof-of-concept reproducible pipeline'
}


// Global default params, used in configs
params {
  version = '0.2dev' //Pipeline version
  //nf_required_version = '0.29.1' //Minimum version of Nextflow required 
  //container = '???/???:latest' // Container slug. Stable releases should specify release tag!
  // Pipeline Options
    url = "ftp://ftp.ensemblgenomes.org/pub/plants/release-38/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz"
    gff3url = "ftp://ftp.ensemblgenomes.org/pub/plants/release-38/gff3/arabidopsis_thaliana/Arabidopsis_thaliana.TAIR10.38.gff3.gz"
    name = "A_thaliana"
  seqerrs = 1.5
  nreads = '100,500'
  nrepeat = 1
  outdir = "./results"
  writeup = "./writeup.Rmd"
  publishmode = "link"
}

//OUTPUT RESULTS PATHS DEFINED HERE, 
//TODO CONSIDER making params.publish-mode dependant on the profile 

profiles {
  standard {
    process.executor = 'local'
  }
  modules {
    includeConfig 'conf/modules.config'
  }
  docker {
    includeConfig 'conf/containers.config'
    includeConfig 'conf/docker.config'
    //docker.runOptions = '-u $(id -u):$(id -g)' //uncomment if encountering permissions issues caused by container defining a custom user (as do  at least some biocontainers)
  }
  ec2 {
    includeConfig 'conf/containers.config'
    includeConfig 'conf/requirements.config'
    includeConfig 'conf/docker.config'
    process.executor = 'ignite'
    // Set max resources for `m5.xlarge`, memory should be less then listed on amazon
    max_cpus = 4
    max_memory = '15GB'
  }
//  awsbatch {
//    includeConfig 'conf/containers.config'
//    process.queue = ''
//    process.executor = 'awsbatch'
//    
//  }
//  k8s {
//    includeConfig 'conf/containers.config'
//    process.executor = 'k8s'
////    process.cpus = 1
////    process.memory = '500 MB'
//  }
  
  slurm {
    includeConfig 'conf/slurm.config'
    includeConfig 'conf/requirements.config'
  }
  singularity {
    includeConfig 'conf/containers.config'
    includeConfig 'conf/singularity.config'
  }
  singularitymodule {
    process.module = 'singularity/2.5.0'
  }
}

includeConfig 'conf/publish.config'

//process {
//    $multiQC.publishDir
//        path = "${params.outdir}/MultiQC"
////        mode = "${params.publishmode}"
//    }
//    $kangaAlign.publishDir {
//        path = "${params.outdir}/BAMs/biokanga"
////        mode = "${params.publishmode}"
//    }
//    $hisat2Align.publishDir {
//        path = "${params.outdir}/BAMs/hisat2"
////        mode = "${params.publishmode}"
//    }
//    $MOCK_generateFigures.publishDir {
//        path = "${params.outdir}/figures"
////        mode = "${params.publishmode}"
//    }
//}

//GENERATE REPORT https://www.nextflow.io/docs/latest/tracing.html#trace-report
report {
    enabled = true
    file = "${params.outdir}/flowinfo/report.html"
}

//GENERATE TIMELINE https://www.nextflow.io/docs/latest/tracing.html#timeline-report
timeline {
    enabled = true
    timeline.file = "${params.outdir}/flowinfo/timeline.html"
}

//GENERATE PIPELINE TRACE https://www.nextflow.io/docs/latest/tracing.html#trace-report
trace {
    enabled = true
    file = "${params.outdir}/flowinfo/trace.txt"
}


//SETTINGS FOR STARTING AND AUTOSCALING A CLUSTER ON AWS EC2 CLOUD
cloud {
    //OPERATING IN 'ap-southeast-2' AWS REGION
    imageId = 'ami-054c4e0bad8549c37' //
    subnetId = 'subnet-57eba230' 
    sharedStorageId = 'fs-d21be5eb' 
    
    //OPERATING IN 'eu-west-1' AWS REGION
//    imageId = 'ami-4b7daa32'
//    subnetId = 'subnet-80f749c8' 
//    sharedStorageId = 'fs-ec6cf125'

    sharedStorageMount = '/mnt/efs'
    instanceType = 't2.medium'
    userName = 'radsuchecki'
    autoscale {
      enabled = true
      minInstances = 1
      maxInstances = 8
      spotPrice = 0.09 
      instanceType = 'm5.xlarge'
      terminateWhenIdle = true
    }
}

//FROM: https://github.com/SciLifeLab/NGI-smRNAseq/blob/29c41afd45011874ed9920c5065ddff93791e3cf/nextflow.config
// Function to ensure that resource requirements don't go beyond a maximum limit
def check_max(obj, type) {
  if(type == 'memory'){
    if(obj.compareTo(params.max_memory) == 1)
      return params.max_memory
    else
      return obj
  } else if(type == 'time'){
    if(obj.compareTo(params.max_time) == 1)
      return params.max_time
    else
      return obj
  } else if(type == 'cpus'){
    return Math.min( obj, params.max_cpus )
  }
}
